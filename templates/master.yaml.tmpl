ignition:
  version: "2.2.0"
storage:
  files:
    - path: /srv/calico-all.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/calico-all.yaml" }}"

    - path: /srv/priority_classes.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/priority_classes.yaml" }}"

    - path: /srv/default-storage-class.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/default-storage-class.yaml" }}"

    - path: /srv/coredns-all.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/coredns-all.yaml" }}"

    - path: /srv/kube-proxy-sa.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/kube-proxy-sa.yaml" }}"

    - path: /srv/kube-proxy-config.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "config/kube-proxy.yaml" }}"

    - path: /srv/kube-proxy-ds.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/kube-proxy-ds.yaml" }}"

    - path: /srv/metrics-server-all.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/metrics-server-all.yaml" }}"

    {{ if eq .Provider "aws" -}}
    - path: /srv/network-policy.json
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/network-policy.json" }}"
    {{ end }}
    - path: /srv/default-backend-dep.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/default-backend-dep.yaml" }}"

    - path: /srv/default-backend-svc.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/default-backend-svc.yaml" }}"

    - path: /srv/ingress-controller-cm.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/ingress-controller-cm.yaml" }}"

    - path: /srv/ingress-controller-sa.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/ingress-controller-sa.yaml" }}"

    - path: /srv/ingress-controller-dep.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/ingress-controller-dep.yaml" }}"

    - path: /srv/ingress-controller-svc.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/ingress-controller-svc.yaml" }}"

    - path: /srv/rbac-roles.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/rbac-roles.yaml" }}"

    - path: /srv/rbac-bindings.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/rbac-bindings.yaml" }}"

    - path: /srv/psp-policies.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/psp-policies.yaml" }}"

    - path: /srv/psp-roles.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/psp-roles.yaml" }}"

    - path: /srv/psp-bindings.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/psp-bindings.yaml" }}"

    - path: /opt/wait-for-domains
      filesystem: root
      mode: 356
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/wait-for-domains" }}"

    - path: /opt/install-debug-tools
      filesystem: root
      mode: 356
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/install-debug-tools" }}"

    - path: /etc/calico/calicoctl.cfg
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/install-debug-tools" }}"

    - path: /etc/crictl.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/crictl.yaml" }}"

    - path: /opt/k8s-addons
      filesystem: root
      mode: 356
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/k8s-addons" }}"

    {{ if eq .Provider "azure" -}}
    - path: /etc/kubernetes/config/azure.yaml
      filesystem: root
      mode: 384
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/azure-master.yaml" }}"

    {{- end }}
    - path: /etc/kubernetes/config/audit-webhook-kube-config.yaml
      filesystem: root
      mode: 384
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "k8s-resource/audit-webhook-kube-config.yaml" }}"

    - path: /etc/kubernetes/kubeconfig/kube-proxy.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "kubeconfig/kube-proxy-master.yaml" }}"

    - path: /etc/kubernetes/config/kubelet.yaml.tmpl
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "config/kubelet-master.yaml.tmpl" }}"

    - path: /etc/kubernetes/config/scheduler.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "config/scheduler.yaml" }}"

    - path: /etc/kubernetes/kubeconfig/addons.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "config/addons.yaml" }}"

    - path: /etc/kubernetes/kubeconfig/kubelet.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "kubeconfig/kubelet-master.yaml" }}"

    - path: /etc/kubernetes/kubeconfig/controller-manager.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "kubeconfig/controller-manager.yaml" }}"

    - path: /etc/kubernetes/kubeconfig/scheduler.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "kubeconfig/scheduler.yaml" }}"

    - path: /etc/tokens/node
      filesystem: root
      mode: 256
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:,VAULT_TOKEN={{ .G8SVaultToken }}"

    - path: /etc/kubernetes/manifests/k8s-api-healthz.yaml
      filesystem: root
      mode: 384
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "manifests/k8s-api-healthz.yaml" }}"


    - path: /etc/kubernetes/manifests/api-server.yaml
      filesystem: root
      mode: 384
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "manifests/api-server.yaml" }}"

    - path: /etc/kubernetes/manifests/controller-manager.yaml
      filesystem: root
      mode: 384
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "manifests/controller-manager.yaml" }}"

    - path: /etc/kubernetes/manifests/scheduler.yaml
      filesystem: root
      mode: 384
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "manifests/scheduler.yaml" }}"

    - path: /etc/kubernetes/config/audit-policy.yaml
      filesystem: root
      mode: 292
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "config/audit-policy.yaml" }}"

    - path: /etc/profile.d/confirm-shutdown.sh
      filesystem: root
      mode: 292
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/confirm-shutdown.sh" }}"

    - path: /etc/profile.d/setup-terminal.sh
      filesystem: root
      mode: 292
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,ZXhwb3J0IFBTMT0iV0FSTklORzogQ09OVFJPTC1QTEFORSBNQVNURVIgfCAkUFMxIg=="

    - path: /etc/profile.d/setup-etcdctl.sh
      filesystem: root
      mode: 292
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/setup-etcdctl.sh" }}"

    - path: /opt/bin/confirm
      filesystem: root
      mode: 365
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/confirm" }}"

    - path: /etc/ssh/sshd_config
      filesystem: root
      mode: 384
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/sshd_config" }}"

    - path: /opt/get-ca.sh
      filesystem: root
      mode: 504
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/get-ca.sh" }}"

    {{ if eq .Provider "azure" -}}
    - path: /etc/udev/rules.d/99-systemd.rules
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/99-systemd.rules" }}"

    {{- end }}
    - path: /etc/sysctl.d/hardening.conf
      filesystem: root
      mode: 384
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/hardening.conf" }}"


    - path: /etc/audit/rules.d/10-docker.rules
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/10-docker.rules" }}"


    - path: /etc/systemd/system/audit-rules.service.d/10-Wait-For-Docker.conf
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/audit-docker-wait.conf" }}"

    - path : /etc/modules-load.d/ipvs.conf
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/ipvs.conf" }}"

systemd:
  units:
  - name: etcd2.service
    enabled: false
    mask: true
  - name: flanneld.service
    enabled: false
    mask: true
  - name: fleet.service
    enabled: false
    mask: true
  - name: fleet.socket
    enabled: false
    mask: true
  - name: update-engine.service
    enabled: false
    mask: true
  - name: locksmithd.service
    enabled: false
    mask: true
  - name: systemd-modules-load.service
    enabled: true
  - name: systemd-networkd-wait-online.service
    enabled: false
    mask: true
  - name: var-lib-etcd.mount
    enabled: {{if eq .Provider "aws" }}false{{else}}true{{end}}
    contents: |
      [Unit]
      Description=Mount disk to /var/lib/etcd
      Before=etcd3.service
      [Mount]
      What=/dev/disk/by-label/var-lib-etcd
      Where=/var/lib/etcd
      Type=ext4
      [Install]
      WantedBy=local-fs.target
{{if eq .Provider "aws" }}
  - name: var-lib-etcd.automount
    enabled: true
    contents: |
      [Unit]
      Description=Mount disk to /var/lib/etcd
      Before=etcd3.service
      After=etcd3-attach-dependencies.service
      [Automount]
      Where=/var/lib/etcd
      [Install]
      WantedBy=multi-user.target
{{end}}
  - name: var-lib-docker.mount
    enabled: true
    contents: |
      [Unit]
      Description=Mount disk to /var/lib/docker
      Before=docker.service
      [Mount]
      What=/dev/disk/by-label/docker
      Where=/var/lib/docker
      Type=xfs
      [Install]
      WantedBy=local-fs.target
  {{if eq .Provider "azure" -}}
  - name: usr-share-oem.mount
    enabled: true
    contents: |
      [Unit]
      Description=Mount OEM to /usr/share/oem
      [Mount]
      What=/dev/sda6
      Where=/usr/share/oem
      Type=ext4
      [Install]
      WantedBy=local-fs.target
  {{ end -}}
  - name: wait-for-domains.service
    enabled: true
    contents: |
      [Unit]
      Description=Wait for etcd, k8s API and vault  domains to be available
      StartLimitInterval=0

      [Service]
      Type=oneshot
      ExecStart=/opt/wait-for-domains

      [Install]
      WantedBy=multi-user.target
  - name: os-hardening.service
    enabled: true
    contents: |
      [Unit]
      Description=Apply os hardening

      [Service]
      Type=oneshot
      ExecStartPre=-/bin/bash -c "gpasswd -d core rkt; gpasswd -d core docker; gpasswd -d core wheel"
      ExecStartPre=/bin/bash -c "until [ -f '/etc/sysctl.d/hardening.conf' ]; do echo Waiting for sysctl file; sleep 1s;done;"
      ExecStart=/usr/sbin/sysctl -p /etc/sysctl.d/hardening.conf

      [Install]
      WantedBy=multi-user.target
  - name: get-vault-ssh-ca.service
    enabled: true
    contents: |
      [Unit]
      Description=get-vault-ssh-ca
      Requires=docker.service get-vault-ca.service
      After=docker.service get-vault-ca.service

      [Service]
      EnvironmentFile=/etc/tokens/node
      Environment=VAULT_ADDR=https://{{ .VaultDomainName }}:443
      Type=oneshot
      RemainAfterExit=yes
      ExecStartPre=/bin/bash -c "while ! curl -q --silent -o /dev/null https://{{ .VaultDomainName }};  do sleep 2s;echo wait for Vault;done;"
      ExecStart=/bin/bash -c '\
         result=$(curl -o /etc/ssh/trusted-user-ca-keys.pem \
                   --header "X-Vault-Token: $VAULT_TOKEN" \
                   $VAULT_ADDR/v1/ssh-client-signer/public_key);\
         [ $? -ne 0 ] && echo "Failed to fetch CA ssh public key" && exit 1 || echo "Successfully retrieved CA ssh public key";'
      [Install]
      WantedBy=multi-user.target
  - name: k8s-setup-kubelet-config.service
    enabled: true
    contents: |
      [Unit]
      Description=k8s-setup-kubelet-config Service
      After=k8s-setup-network-env.service docker.service
      Requires=k8s-setup-network-env.service docker.service

      [Service]
      EnvironmentFile=/etc/network-environment
      ExecStart=/bin/bash -c '/usr/bin/envsubst </etc/kubernetes/config/kubelet.yaml.tmpl >/etc/kubernetes/config/kubelet.yaml'

      [Install]
      WantedBy=multi-user.target
  - name: docker.service
    enabled: true
    dropins:
    - name: 10-giantswarm-extra-args.conf
      contents: |
        [Unit]
        Requires=var-lib-docker.mount
        After=var-lib-docker.mount

        [Service]
        Environment="DOCKER_CGROUPS=--exec-opt native.cgroupdriver=cgroupfs --log-opt max-size=50m --log-opt max-file=2 --log-opt labels=io.kubernetes.container.hash,io.kubernetes.container.name,io.kubernetes.pod.name,io.kubernetes.pod.namespace,io.kubernetes.pod.uid"
        Environment="DOCKER_OPT_BIP=--bip={{ .DockerCIDR }}"
        Environment="DOCKER_OPTS=--live-restore --userland-proxy=false --icc=false"
  - name: k8s-setup-network-env.service
    enabled: true
    contents: |
      [Unit]
      Description=k8s-setup-network-env Service
      Requires=network.target docker.service{{if eq .Provider "azure" }} waagent.service{{ end }}
      After=network.target docker.service{{if eq .Provider "azure" }} waagent.service{{ end }}

      [Service]
      Type=oneshot
      RemainAfterExit=yes
      Environment="IMAGE={{.DockerRegistry}}/giantswarm/k8s-setup-network-environment:68e90113331feca3b9ffe6a75a601b381ba8c1f7"
      Environment="NAME=%p.service"
      Environment="NETWORK_CONFIG_CONTAINER="
      ExecStartPre=/usr/bin/mkdir -p /opt/bin/
      ExecStartPre=/usr/bin/docker pull $IMAGE
      ExecStartPre=-/usr/bin/docker stop -t 10 $NAME
      ExecStartPre=-/usr/bin/docker rm -f $NAME
      ExecStart=/usr/bin/docker run --rm --net=host -v /etc:/etc --name $NAME $IMAGE
      ExecStop=-/usr/bin/docker stop -t 10 $NAME
      ExecStopPost=-/usr/bin/docker rm -f $NAME
      [Install]
      WantedBy=multi-user.target

  - name: get-vault-ca.service
    enabled: true
    contents: |
      [Unit]
      Description=get vault-ca into trusted certs
      Before=calico-certs.service api-certs.service etcd3-certs.service
      After=wait-for-domains.service{{if eq .Provider "azure" }} waagent.service{{ end }}
      Requires=wait-for-domains.service{{if eq .Provider "azure" }} waagent.service{{ end }}

      [Service]
      Type=oneshot
      ExecStartPre=/opt/get-ca.sh {{ .VaultDomainName }}:443 /etc/ssl/certs/gs-ca.pem
      ExecStart=/sbin/update-ca-certificates
      RemainAfterExit=yes
      [Install]
      WantedBy=multi-user.target
  - name: calico-certs.service
    enabled: true
    contents: |
      [Unit]
      Description=calico-certs
      Requires=get-vault-ca.service k8s-setup-network-env.service docker.service wait-for-domains.service{{if eq .Provider "azure" }} waagent.service{{ end }}
      After=get-vault-ca.service k8s-setup-network-env.service docker.service wait-for-domains.service{{if eq .Provider "azure" }} waagent.service{{ end }}

      [Service]
      EnvironmentFile=/etc/environment
      EnvironmentFile=/etc/network-environment
      EnvironmentFile=/etc/tokens/node
      Type=oneshot
      RemainAfterExit=yes
      ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/ssl/calico/
      ExecStartPre=/bin/bash -c "while ! docker run --rm -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt {{.DockerRegistry}}/giantswarm/curl:7.67.0 -k -q --silent -o /dev/null https://{{ .VaultDomainName }};  do sleep 2s;echo wait for Vault;done;"
      ExecStart=/bin/bash -c '\
        RETRY=3;\
        while [ -z "$result" ] && [ $RETRY -gt 0 ]; do\
        sleep 2s; echo "Trying to issue calico certs...";\
        let RETRY=$RETRY-1;\
        export result=$(\
          /usr/bin/docker run \
          --rm \
          --net=host \
          -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt \
          -v /etc/kubernetes/ssl/calico/:/etc/kubernetes/ssl/calico/ \
          {{.DockerRegistry}}/giantswarm/certctl:943e40d9c36efc2eec76783d48a891fc6f323493 \
          issue \
          --vault-addr=https://{{ .VaultDomainName }} \
          --vault-token=${VAULT_TOKEN} \
          --cluster-id=g8s \
          --common-name={{ .ETCDDomainName }} \
          --ttl=8760h \
          --ip-sans=127.0.0.1,${DEFAULT_IPV4} \
          --alt-names=localhost \
          --ca-file=/etc/kubernetes/ssl/calico/etcd-ca \
          --crt-file=/etc/kubernetes/ssl/calico/etcd-cert \
          --key-file=/etc/kubernetes/ssl/calico/etcd-key); \
        done; \
        [ -z "$result" ] && echo "Failed to issue calico certs." && exit 1 || echo "Successfully issued calico certs.";'
      ExecStop=/usr/bin/rm -rf /etc/kubernetes/ssl/calico/
      [Install]
      WantedBy=multi-user.target
  - name: etcd3-certs.service
    enabled: true
    contents: |
      [Unit]
      Description=etcd3-certs
      Requires=get-vault-ca.service k8s-setup-network-env.service docker.service
      After=get-vault-ca.service k8s-setup-network-env.service docker.service

      [Service]
      EnvironmentFile=/etc/environment
      EnvironmentFile=/etc/network-environment
      EnvironmentFile=/etc/tokens/node
      Type=oneshot
      RemainAfterExit=yes
      ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/ssl/etcd/
      ExecStartPre=/bin/bash -c "while ! docker run --rm -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt {{.DockerRegistry}}/giantswarm/curl:7.67.0 -k -q --silent -o /dev/null https://{{ .VaultDomainName }};  do sleep 2s;echo wait for Vault;done;"
      ExecStart=/bin/bash -c '\
        RETRY=3;\
        while [ -z "$result" ] && [ $RETRY -gt 0 ]; do\
        sleep 2s; echo "Trying to issue etcd certs...";\
        let RETRY=$RETRY-1;\
        export result=$(\
          /usr/bin/docker run \
          --rm \
          --net=host \
          -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt \
          -v /etc/kubernetes/ssl/etcd/:/etc/kubernetes/ssl/etcd/ \
          {{.DockerRegistry}}/giantswarm/certctl:943e40d9c36efc2eec76783d48a891fc6f323493 \
          issue \
          --vault-addr=https://{{ .VaultDomainName }} \
          --vault-token=${VAULT_TOKEN} \
          --cluster-id=g8s \
          --common-name={{ .ETCDDomainName }} \
          --ttl=8760h \
          --crt-file=/etc/kubernetes/ssl/etcd/server-crt.pem \
          --ip-sans=127.0.0.1,${DEFAULT_IPV4} \
          --alt-names=localhost,etcd{{ .MasterID }}.{{ .BaseDomain }} \
          --key-file=/etc/kubernetes/ssl/etcd/server-key.pem \
          --ca-file=/etc/kubernetes/ssl/etcd/server-ca.pem); \
        done; \
        [ -z "$result" ] && echo "Failed to issue etcd certs." && exit 1 || echo "Successfully issued etcd certs.";'
      ExecStartPost=/bin/cp /etc/kubernetes/ssl/etcd/server-crt.pem /etc/kubernetes/ssl/etcd/client-crt.pem
      ExecStartPost=/bin/cp /etc/kubernetes/ssl/etcd/server-ca.pem /etc/kubernetes/ssl/etcd/client-ca.pem
      ExecStartPost=/bin/cp /etc/kubernetes/ssl/etcd/server-key.pem /etc/kubernetes/ssl/etcd/client-key.pem
      ExecStop=/usr/bin/rm -rf /etc/kubernetes/ssl/etcd/
      [Install]
      WantedBy=multi-user.target
{{ if eq .Provider "aws" }}
  - name: etcd3-attach-dependencies.service
    enabled: true
    contents: |
      [Unit]
      Description=Attach etcd dependencies
      Requires=network.target
      After=network.target

      [Service]
      Environment="IMAGE={{.DockerRegistry}}/giantswarm/aws-attach-etcd-dep:f6a1d8eb340032f9dc2519dd974797487125b1a7"
      Environment="NAME=%p.service"
      Type=oneshot
      RemainAfterExit=yes
      ExecStart=/bin/bash -c "docker run --rm -i \
                        -v /dev:/dev \
                        --privileged \
                        --name ${NAME} \
                        ${IMAGE} \
                        --eni-device-index=1 \
                        --eni-tag-key=Name \
                        --eni-tag-value={{.ClusterName}}-master{{.MasterID}}-etcd \
                        --volume-device-name=/dev/xvdh \
                        --volume-device-filesystem-type=ext4 \
                        --volume-tag-key=Name \
                        --volume-tag-value={{.ClusterName}}-master{{.MasterID}}-etcd"
      [Install]
      WantedBy=multi-user.target
{{ end }}
  - name: etcd3.service
    enabled: true
    contents: |
      [Unit]
      Description=etcd3
      Requires=k8s-setup-network-env.service etcd3-certs.service calico-certs.service {{if eq .Provider "aws" }}etcd3-attach-dependencies.service{{else}}var-lib-etcd.mount{{end}}
      After=k8s-setup-network-env.service etcd3-certs.service calico-certs.service {{if eq .Provider "aws" }}etcd3-attach-dependencies.service{{else}}var-lib-etcd.mount{{end}}
      Conflicts=etcd.service etcd2.service
      StartLimitIntervalSec=0

      [Service]
      Restart=always
      RestartSec=0
      TimeoutStopSec=10
      LimitNOFILE=40000
      Environment=IMAGE={{.DockerRegistry}}/giantswarm/etcd:v3.4.4
      Environment=NAME=%p.service
      EnvironmentFile=/etc/network-environment
      ExecStartPre=-/usr/bin/docker stop  $NAME
      ExecStartPre=-/usr/bin/docker rm  $NAME
      ExecStartPre=-/usr/bin/docker pull $IMAGE
      ExecStartPre=/bin/bash -c "while [ ! -f /etc/kubernetes/ssl/etcd/server-ca.pem ]; do echo 'Waiting for /etc/kubernetes/ssl/etcd/server-ca.pem to be written' && sleep 1; done"
      ExecStartPre=/bin/bash -c "while [ ! -f /etc/kubernetes/ssl/etcd/server-crt.pem ]; do echo 'Waiting for /etc/kubernetes/ssl/etcd/server-crt.pem to be written' && sleep 1; done"
      ExecStartPre=/bin/bash -c "while [ ! -f /etc/kubernetes/ssl/etcd/server-key.pem ]; do echo 'Waiting for /etc/kubernetes/ssl/etcd/server-key.pem to be written' && sleep 1; done"
      ExecStart=/usr/bin/docker run \
          -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt \
          -v /etc/kubernetes/ssl/etcd/:/etc/etcd \
          -v /var/lib/etcd/:/var/lib/etcd  \
          --net=host  \
          --name $NAME \
          $IMAGE \
          etcd \
          --name etcd{{ .MasterID }} \
          --trusted-ca-file /etc/etcd/server-ca.pem \
          --cert-file /etc/etcd/server-crt.pem \
          --key-file /etc/etcd/server-key.pem \
          --client-cert-auth=true \
          --peer-trusted-ca-file /etc/etcd/server-ca.pem \
          --peer-cert-file /etc/etcd/server-crt.pem \
          --peer-key-file /etc/etcd/server-key.pem \
          --peer-client-cert-auth=true \
          --advertise-client-urls=https://{{ .ETCDDomainName }}:2379 \
          --initial-advertise-peer-urls=https://{{ .ETCDDomainName }}:2380 \
          --listen-client-urls=https://0.0.0.0:2379 \
          --listen-peer-urls=https://{{if eq .Provider "aws"}}{{.MasterENIAddress}}{{else}}${DEFAULT_IPV4}{{end}}:2380 \
          --initial-cluster-token=k8s-etcd-cluster \
          {{- if eq .MasterCount "3" }}
          --initial-cluster={{ .ETCDInitialClusterMulti }} \
          {{- else }}
          --initial-cluster={{ .ETCDInitialClusterSingle }} \
          {{- end }}
          --initial-cluster-state new \
          --data-dir=/var/lib/etcd \
          --enable-v2

      [Install]
      WantedBy=multi-user.target
  - name: etcd3-defragmentation.service
    enabled: false
    contents: |
      [Unit]
      Description=etcd defragmentation job
      After=docker.service etcd3.service
      Requires=docker.service etcd3.service

      [Service]
      Type=oneshot
      EnvironmentFile=/etc/environment
      Environment=IMAGE={{.DockerRegistry}}/giantswarm/etcd:v3.4.4
      Environment=NAME=%p.service
      ExecStartPre=-/usr/bin/docker stop  $NAME
      ExecStartPre=-/usr/bin/docker rm  $NAME
      ExecStartPre=-/usr/bin/docker pull $IMAGE
      ExecStart=/usr/bin/docker run \
        -v /etc/kubernetes/ssl/etcd/:/etc/etcd \
        --net=host  \
        -e ETCDCTL_API=3 \
        --name $NAME \
        $IMAGE \
        etcdctl \
        --endpoints https://{{ .ETCDDomainName }}:2379 \
        --cacert /etc/etcd/server-ca.pem \
        --cert /etc/etcd/server-crt.pem \
        --key /etc/etcd/server-key.pem \
        defrag  \
          --command-timeout=60s \
          --dial-timeout=60s \
          --keepalive-timeout=25s

      [Install]
      WantedBy=multi-user.target
  - name: etcd3-defragmentation.timer
    enabled: true
    contents: |
      [Unit]
      Description=Execute etcd3-defragmentation every day at 3.30AM UTC

      [Timer]
      OnCalendar=*-*-* 03:30:00 UTC

      [Install]
      WantedBy=multi-user.target
{{if eq .Provider "aws" }}
  - name: set-hostname.service
    enabled: true
    contents: |
      [Unit]
      Description=set proper hostname for k8s
      Requires=wait-for-domains.service
      After=wait-for-domains.service
      Before=k8s-kubelet.service

      [Service]
      Type=oneshot
      RemainAfterExit=yes
      ExecStart=/bin/bash -c "hostnamectl set-hostname $(curl http://169.254.169.254/latest/meta-data/local-hostname)"

      [Install]
      WantedBy=multi-user.target
{{end}}
  - name: k8s-setup-download-hyperkube.service
    enabled: true
    contents: |
      [Unit]
      Description=Pulls hyperkube binary from image to local FS
      After=docker.service
      Requires=docker.service
      [Service]
      Type=oneshot
      RemainAfterExit=yes
      TimeoutStartSec=0
      Environment="IMAGE={{.DockerRegistry}}/giantswarm/hyperkube:{{.K8sVersion}}"
      Environment="NAME=%p.service"
      ExecStartPre=/bin/bash -c "/usr/bin/docker create --name $NAME $IMAGE"
      ExecStart=/bin/bash -c "/usr/bin/docker cp $NAME:/hyperkube /opt/bin/hyperkube"
      ExecStartPost=/bin/bash -c "/usr/bin/docker rm $NAME"
      [Install]
      WantedBy=multi-user.target
  - name: k8s-kubelet.service
    enabled: true
    contents: |
      [Unit]
      Description=k8s-kubelet
      StartLimitIntervalSec=0
      After=k8s-setup-network-env.service docker.service calico-certs.service api-certs.service wait-for-domains.service k8s-setup-kubelet-config.service k8s-setup-download-hyperkube.service
      Requires=k8s-setup-network-env.service docker.service calico-certs.service api-certs.service wait-for-domains.service k8s-setup-kubelet-config.service k8s-setup-download-hyperkube.service

      [Service]
      TimeoutStartSec=300
      Restart=always
      RestartSec=0
      TimeoutStopSec=10
      EnvironmentFile=/etc/network-environment
      Environment="NAME=%p.service"
      Environment="ETCD_CA_CERT_FILE=/etc/kubernetes/ssl/etcd/client-ca.pem"
      Environment="ETCD_CERT_FILE=/etc/kubernetes/ssl/etcd/client-crt.pem"
      Environment="ETCD_KEY_FILE=/etc/kubernetes/ssl/etcd/client-key.pem"
      ExecStart=/opt/bin/hyperkube kubelet \
      --config=/etc/kubernetes/config/kubelet.yaml \
      --node-ip=${DEFAULT_IPV4} \
      --container-runtime-endpoint=/var/run/dockershim/dockershim.sock \
      --enable-server \
      --logtostderr=true \
      {{if eq .Provider "aws" -}}
      --cloud-provider=aws \
      --image-pull-progress-deadline={{ .ImagePullProgressDeadline }} \
      --pod-infra-container-image={{.DockerRegistry}}/{{ .PodInfraImage }} \
      {{ else -}}
      --cloud-provider=azure \
      --cloud-config=/etc/kubernetes/config/azure.yaml \
      {{ end -}}
      --network-plugin=cni \
      --register-node=true \
      --kubeconfig=/etc/kubernetes/kubeconfig/kubelet.yaml \
      --node-labels="node.kubernetes.io/master,role=master,ip=${DEFAULT_IPV4},master-id={{.MasterID}}" \
      --v=2
      ExecStop=-/usr/bin/docker stop -t 10 $NAME
      ExecStopPost=-/usr/bin/docker rm -f $NAME

      [Install]
      WantedBy=multi-user.target
  - name: k8s-label-node.service
    enabled: true
    contents: |
      [Unit]
      Description=Adds labels to the node after kubelet startup
      After=k8s-kubelet.service
      Wants=k8s-kubelet.service
      [Service]
      Type=oneshot
      RemainAfterExit=yes
      Environment="KUBECTL=/opt/bin/hyperkube kubectl --kubeconfig /etc/kubernetes/kubeconfig/kubelet.yaml"
      ExecStart=/bin/sh -c '\
        while [ "$($KUBECTL get nodes $(hostname | tr '[:upper:]' '[:lower:]')| wc -l)" -lt "1" ]; do echo "Waiting for healthy k8s" && sleep 20s;done; \
        $KUBECTL label nodes --overwrite $(hostname | tr '[:upper:]' '[:lower:]') node-role.kubernetes.io/master=""; \
        $KUBECTL label nodes --overwrite $(hostname | tr '[:upper:]' '[:lower:]') kubernetes.io/role=master'
      [Install]
      WantedBy=multi-user.target
  - name: api-certs.service
    enabled: true
    contents: |
      [Unit]
      Description=api-certs
      Requires=get-vault-ca.service k8s-setup-network-env.service docker.service wait-for-domains.service{{if eq .Provider "azure" }} waagent.service{{ end }}
      After=get-vault-ca.service k8s-setup-network-env.service docker.service wait-for-domains.service{{if eq .Provider "azure" }} waagent.service{{ end }}

      [Service]
      EnvironmentFile=/etc/environment
      EnvironmentFile=/etc/network-environment
      EnvironmentFile=/etc/tokens/node
      Environment=VAULT_ADDR=https://{{ .VaultDomainName }}
      Type=oneshot
      RemainAfterExit=yes
      ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/ssl/
      ExecStartPre=/bin/bash -c "while ! docker run --rm -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt {{.DockerRegistry}}/giantswarm/curl:7.67.0 -k -q --silent -o /dev/null https://{{ .VaultDomainName }};  do sleep 2s;echo wait for Vault;done;"
      ExecStartPre=/bin/bash -c '\
        RETRY=3;\
        while [ -z "$rsa_key" ] && [ $RETRY -gt 0 ]; do\
        sleep 2s; echo "trying to get g8s_sa_sign_key...";\
        let RETRY=$RETRY-1;\
        export rsa_key=$(\
        docker run --rm -i\
        -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt\
        --net host\
        --privileged=true\
        -e VAULT_ADDR\
        -e VAULT_TOKEN\
        {{.DockerRegistry}}/giantswarm/vault:0.10.3\
        kv get -field=key secret/g8s_sa_sign_key 2>/dev/null\
       );\
       done;\
       [ -z "$rsa_key" ] && echo "Failed to fetch g8s_sa_key" && exit 1 || echo "Successfully retrieved g8s_sa_key";\
       echo -e "-----BEGIN RSA PRIVATE KEY-----\n$rsa_key\n-----END RSA PRIVATE KEY-----" > /etc/kubernetes/ssl/service-account-key.pem'
      ExecStart=/usr/bin/docker run \
      --rm \
      --net=host \
      -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt \
      -v /etc/kubernetes/ssl/:/etc/kubernetes/ssl/ \
      {{.DockerRegistry}}/giantswarm/certctl:943e40d9c36efc2eec76783d48a891fc6f323493 \
      issue \
      --vault-addr=${VAULT_ADDR} \
      --vault-token=${VAULT_TOKEN} \
      --cluster-id=g8s \
      --common-name={{ .APIDomainName }} \
      --ttl=8760h \
      --crt-file=/etc/kubernetes/ssl/apiserver-crt.pem \
      --ip-sans=127.0.0.1,${DEFAULT_IPV4},{{ .K8SAPIIP }} \
      --alt-names=localhost,kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.local \
      --allowed-domains={{.BaseDomain}},localhost,kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.local \
      --allow-bare-domains=true \
      --organizations=system:masters \
      --key-file=/etc/kubernetes/ssl/apiserver-key.pem \
      --ca-file=/etc/kubernetes/ssl/apiserver-ca.pem
      [Install]
      WantedBy=multi-user.target
  - name: k8s-addons.service
    enabled: true
    contents: |
      [Unit]
      Description=Kubernetes Addons
      Wants=k8s-kubelet.service
      After=k8s-kubelet.service
      [Service]
      Type=oneshot
      EnvironmentFile=/etc/network-environment
      ExecStart=/opt/k8s-addons
      [Install]
      WantedBy=multi-user.target
  - name: debug-tools.service
    enabled: true
    contents: |
      [Unit]
      Description=Calicoctl and crictl tools
      After=network-online.target
      [Service]
      Type=oneshot
      ExecStartPre=/bin/sleep 30
      ExecStart=/opt/install-debug-tools
      [Install]
      WantedBy=multi-user.target
{{ if .LogentriesEnabled }}
  - name: logentries.service
    enabled: true
    contents: |
      [Unit]
      Description=Logentries

      [Service]
      Environment=LOGENTRIES_PREFIX={{ .LogentriesPrefix }}
      Environment=LOGENTRIES_TOKEN={{ .LogentriesToken }}
      ExecStart=/bin/sh /opt/bin/logentries.sh ${LOGENTRIES_PREFIX} ${LOGENTRIES_TOKEN}

      [Install]
      WantedBy=multi-user.target
{{ end -}}
{{ if eq .Provider "aws" -}}
networkd:
  units:
  - name: 10-eth1.network
    contents: |
      # ensure that traffic arriving on eth1 leaves again from eth1 to prevent asymetric routing
      [Match]
      Name=eth1
      [Network]
      Address={{.MasterENIAddress}}/{{.MasterENISubnetSize}}
      
      [RoutingPolicyRule]
      Table=2
      From={{.MasterENIAddress}}/32
      
      [Route]
      Destination=0.0.0.0/0
      Gateway={{.MasterENIGateway}}
      Table=2
{{ end -}}
storage:
  filesystems:
    - name: docker
      mount:
        device: {{if eq .Provider "azure" }}/dev/disk/azure/scsi1/lun0{{else}}{{ .MasterMountDocker }}{{end}}
        format: xfs
        wipe_filesystem: false
        label: docker
{{if eq .Provider "azure" }}
    - name: etcd
      mount:
        device: /dev/disk/azure/scsi1/lun1
        format: ext4
        wipe_filesystem: false
        label: var-lib-etcd
{{end}}
{{ .Users }}
